{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfdd121",
      "metadata": {
        "id": "cbfdd121",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# скачивание и распаковка проекта, распаковка данных\n",
        "!wget https://github.com/gimaevra94/gan/archive/refs/heads/main.zip\n",
        "!unzip /content/main.zip\n",
        "!unzip /content/gan-main/data.zip\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "class DCGAN(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # лосс, инициализатор весов, оптимайзер, генератор, дискриминатор\n",
        "        self.loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.init=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "        self.optimizer = tf.keras.optimizers.legacy.Adam(0.0002, beta_1=0.5, beta_2=0.999)\n",
        "        self.generator = self._build_generator()\n",
        "        self.discriminator = self._build_discriminator()\n",
        "\n",
        "    def discriminator_loss(self, real_output, fake_output):\n",
        "        \"\"\"считает ошибку между выходами дискриминатора и метками классов 1,0\"\"\"\n",
        "        real_loss = self.loss(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = self.loss(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    def generator_loss(self, fake_output):\n",
        "        \"\"\"считает ошибку между выходом дискриминатора и метками класса 1\"\"\"\n",
        "        return self.loss(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    def _build_generator(self):\n",
        "        \"\"\"принимает вектор из нормального распределения\n",
        "        и  постепенно уменьшая количество каналов\n",
        "        и увеличивая размер изображения превращает его в 80,80,1\"\"\"\n",
        "        model_gen = tf.keras.Sequential([\n",
        "            tf.keras.layers.Reshape(target_shape=(1, 1, 200), input_shape=(200,)),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(4),\n",
        "            tf.keras.layers.Conv2D(256,\n",
        "                            kernel_size=4,\n",
        "                            padding=\"same\",\n",
        "                            use_bias=False,\n",
        "                            kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(128,\n",
        "                            kernel_size=4,\n",
        "                            padding=\"same\",\n",
        "                            use_bias=False,\n",
        "                            kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(64,\n",
        "                            kernel_size=4,\n",
        "                            padding=\"same\",\n",
        "                            use_bias=False,\n",
        "                            kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(1,\n",
        "                            kernel_size=4,\n",
        "                            strides=1,\n",
        "                            activation=\"tanh\",\n",
        "                            padding=\"same\",\n",
        "                            kernel_initializer=self.init)])\n",
        "        return model_gen\n",
        "\n",
        "    def _build_discriminator(self):\n",
        "        \"\"\"принимает на вход реальное изображение\n",
        "        либо сгенерированное. Постепенно уменьшает его до вектора логитов\"\"\"\n",
        "        model_disc = tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=((32,32,1))),\n",
        "\n",
        "            tf.keras.layers.Conv2D(64,\n",
        "                              kernel_size=4,\n",
        "                              padding=\"same\",\n",
        "                              use_bias=False,\n",
        "                              kernel_initializer=self.init,\n",
        "                              strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(128,\n",
        "                                kernel_size=4,\n",
        "                                padding=\"same\",\n",
        "                                use_bias=False,\n",
        "                                kernel_initializer=self.init,\n",
        "                                strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(256,\n",
        "                                kernel_size=4,\n",
        "                                padding=\"same\",\n",
        "                                use_bias=False,\n",
        "                                kernel_initializer=self.init,\n",
        "                                strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(1,kernel_size=4,kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.Flatten()])\n",
        "\n",
        "        return model_disc\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, images):\n",
        "        \"\"\"1. генератор принимает вектор нормального распределения и выдает фейк.данные\n",
        "           2. дискриминатор принимает фейк.данные генератора и реальные данные\n",
        "           3. выход дискриминатора на реальных и фейк.данных едет в discriminator_loss\n",
        "           4. выход дискриминатора на фейк.данных едет в generator_loss\n",
        "           5. с помощью лосса генератора и обученных параметров генератора\n",
        "           считается градиент для генератора. аналогично для дискриминатора\n",
        "           6. оба градиента пробрасываются в оптимайзер\"\"\"\n",
        "        noise = tf.random.normal([tf.cast(images.shape[0], tf.int32),200])\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = self.generator(noise, training=True)\n",
        "\n",
        "            real_output = self.discriminator(images, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            gen_loss = self.generator_loss(fake_output)\n",
        "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n",
        "    def train(self, dataset):\n",
        "      \"\"\"каждую итерацию один батч реальных данных едет в метод train_step,\n",
        "      откуда поедет на вход дискриминатора\"\"\"\n",
        "        for epoch in range(5):\n",
        "            for image_batch in tqdm(dataset):\n",
        "                self.train_step(image_batch)\n",
        "\n",
        "gan = DCGAN()\n",
        "\n",
        "#path='C:/Users/gimaevra94/Documents/local/gan/data'\n",
        "path='/content'\n",
        "\n",
        "data=pathlib.Path(path).parent/'data'\n",
        "data2=data/'data2'\n",
        "data3=data2/'data3'\n",
        "\n",
        "train=tf.keras.utils.image_dataset_from_directory(directory=data2,\n",
        "                                                  label_mode=None,\n",
        "                                                  batch_size=256,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  image_size=(80,80))\n",
        "\n",
        "norm  = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "train = train.map(lambda x: norm(x))\n",
        "\n",
        "gan.train(train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}