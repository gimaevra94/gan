{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfdd121",
      "metadata": {
        "id": "cbfdd121",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# скачивание и распаковка проекта, распаковка данных\n",
        "!wget https://github.com/gimaevra94/gan/archive/refs/heads/main.zip\n",
        "!unzip /content/main.zip\n",
        "!unzip /content/gan-main/data.zip\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "class Gan(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # лосс, инициализатор весов, оптимайзер, генератор, дискриминатор\n",
        "        self.loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.init=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n",
        "        self.opti=tf.keras.optimizers.legacy.Adam(0.0002,beta_1=0.5,beta_2=0.999)\n",
        "        self.gen=self.gen()\n",
        "        self.disc=self.disc()\n",
        "\n",
        "    def loss_gen(self,output_fake):\n",
        "        \"\"\"считает ошибку на основе фейкового выхода дискриминатора и метки класса 1\"\"\"\n",
        "        return self.loss(tf.ones_like(output_fake),output_fake)\n",
        "\n",
        "    def loss_disc(self,output_real,output_fake):\n",
        "        \"\"\"считает ошибку на основе фейкового и реального выходов дискриминатора и метками классов 1,0\"\"\"\n",
        "        loss_real=self.loss(tf.ones_like(output_real),output_real)\n",
        "        loss_fake=self.loss(tf.zeros_like(output_fake),output_fake)\n",
        "        return loss_real+loss_fake\n",
        "\n",
        "    def gen(self):\n",
        "        \"\"\"принимает вектор из нормального распределения и превращает его в размерность 80,80,1\"\"\"\n",
        "        model=tf.keras.Sequential([\n",
        "            tf.keras.layers.Reshape(target_shape=(1,1,100),input_shape=(100,)),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(10),\n",
        "            tf.keras.layers.Conv2D(256,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(128,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(64,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.UpSampling2D(),\n",
        "            tf.keras.layers.Conv2D(1,\n",
        "                                   kernel_size=4,\n",
        "                                   strides=1,\n",
        "                                   activation=\"tanh\",\n",
        "                                   padding=\"same\",\n",
        "                                   kernel_initializer=self.init)])\n",
        "        return model\n",
        "\n",
        "    def disc(self):\n",
        "        \"\"\"принимает реальное изображение либо сгенерированное\n",
        "        превращает его в вектор логитов\"\"\"\n",
        "        model=tf.keras.Sequential([\n",
        "            tf.keras.layers.InputLayer(input_shape=((80,80,1))),\n",
        "\n",
        "            tf.keras.layers.Conv2D(64,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init,\n",
        "                                   strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(128,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init,\n",
        "                                   strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(256,\n",
        "                                   kernel_size=4,\n",
        "                                   padding=\"same\",\n",
        "                                   use_bias=False,\n",
        "                                   kernel_initializer=self.init,\n",
        "                                   strides=2),\n",
        "\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(1,kernel_size=4,kernel_initializer=self.init),\n",
        "\n",
        "            tf.keras.layers.Flatten()])\n",
        "\n",
        "        return model\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self,imgs_real):\n",
        "        \"\"\"1. генератор принимает вектор нормального распределения и выдает фейк.данные\n",
        "           2. дискриминатор принимает реальные данные и фейк.данные генератора\n",
        "           3. выход дискриминатора на реальных и фейк.данных едет в loss_disc\n",
        "           4. выход дискриминатора на фейк.данных едет в loss_gen\n",
        "           5. с помощью лосса генератора и обученных параметров генератора\n",
        "           считается градиент для генератора. аналогично для дискриминатора\n",
        "           6. оба градиента передаются в оптимайзер\"\"\"\n",
        "        random_normal_vector=tf.random.normal([tf.cast(imgs_real.shape[0],tf.int32),100])\n",
        "\n",
        "        with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
        "            imgs_generated=self.gen(random_normal_vector,training=True)\n",
        "\n",
        "            output_real=self.disc(imgs_real,training=True)\n",
        "            output_fake=self.disc(imgs_generated,training=True)\n",
        "\n",
        "            loss_gen=self.loss_gen(output_fake)\n",
        "            loss_disc=self.loss_disc(output_real,output_fake)\n",
        "\n",
        "        grads_of_gen=gen_tape.gradient(loss_gen,self.gen.trainable_variables)\n",
        "        grads_of_disc=disc_tape.gradient(loss_disc,self.disc.trainable_variables)\n",
        "\n",
        "        self.opti.apply_gradients(zip(grads_of_gen,self.gen.trainable_variables))\n",
        "        self.opti.apply_gradients(zip(grads_of_disc,self.disc.trainable_variables))\n",
        "\n",
        "    def train(self,data):\n",
        "        \"\"\"каждую итерацию один батч реальных данных едет на вход дискриминатора\"\"\"\n",
        "        for epoch in range(100):\n",
        "            for batch in tqdm(data):\n",
        "                self.train_step(batch)\n",
        "\n",
        "gan=Gan()\n",
        "\n",
        "path='content/'\n",
        "\n",
        "data=pathlib.Path(path).parent/'data'\n",
        "data2=data/'data2'\n",
        "data3=data2/'data3'\n",
        "\n",
        "train=tf.keras.utils.image_dataset_from_directory(directory=data2,\n",
        "                                                  label_mode=None,\n",
        "                                                  batch_size=256,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  image_size=(80,80))\n",
        "\n",
        "rescale=tf.keras.layers.Rescaling(1./127.5,offset=-1)\n",
        "train=train.map(lambda x:rescale(x))\n",
        "\n",
        "gan.train(train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}