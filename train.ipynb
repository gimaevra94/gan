{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbfdd121",
   "metadata": {
    "id": "cbfdd121",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24012 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gimaevra94\\AppData\\Local\\Temp\\ipykernel_1760\\2812642321.py:152: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm(data):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651d744967ae413b858a16e2b93923f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m rescale\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m127.5\u001b[39m,offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    171\u001b[0m train\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x:rescale(x))\n\u001b[1;32m--> 173\u001b[0m gan\u001b[38;5;241m.\u001b[39mtrain(train)\n",
      "Cell \u001b[1;32mIn[18], line 153\u001b[0m, in \u001b[0;36mGan.train\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data):\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(batch)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# скачивание и распаковка проекта, распаковка данных\n",
    "\"\"\"!wget https://github.com/gimaevra94/gan/archive/refs/heads/main.zip\n",
    "!unzip /content/main.zip\n",
    "!unzip /content/gan-main/data.zip\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class Gan(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # лосс, инициализатор весов, оптимайзер, генератор, дискриминатор\n",
    "        self.loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.init=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n",
    "        self.opti=tf.keras.optimizers.legacy.Adam(0.0002,beta_1=0.5,beta_2=0.999)\n",
    "        self.gen=self.gen()\n",
    "        self.disc=self.disc()\n",
    "        \n",
    "    def loss_gen(self,output_fake):\n",
    "        \"\"\"считает ошибку между выходом дискриминатора и метками класса 1\"\"\"\n",
    "        return self.loss(tf.ones_like(output_fake),output_fake)\n",
    "\n",
    "    def loss_disc(self,output_real,output_fake):\n",
    "        \"\"\"считает ошибку между выходами дискриминатора и метками классов 1,0\"\"\"\n",
    "        loss_real=self.loss(tf.ones_like(output_real),output_real)\n",
    "        loss_fake=self.loss(tf.zeros_like(output_fake),output_fake)\n",
    "        return loss_real +loss_fake\n",
    "\n",
    "    def gen(self):\n",
    "        \"\"\"принимает вектор из нормального распределения\n",
    "        и  постепенно уменьшая количество каналов\n",
    "        и увеличивая размер изображения превращает его в 80,80,1\"\"\"\n",
    "        model=tf.keras.Sequential([\n",
    "            tf.keras.layers.Reshape(target_shape=(1,1,200),input_shape=(200,)),\n",
    "\n",
    "            tf.keras.layers.UpSampling2D(10),\n",
    "            tf.keras.layers.Conv2D(256,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(128,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(64,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(1,\n",
    "                                   kernel_size=4,\n",
    "                                   strides=1,\n",
    "                                   activation=\"tanh\",\n",
    "                                   padding=\"same\",\n",
    "                                   kernel_initializer=self.init)])\n",
    "        return model\n",
    "\n",
    "    def disc(self):\n",
    "        \"\"\"принимает на вход реальное изображение\n",
    "        либо сгенерированное. Постепенно уменьшает его до вектора логитов\"\"\"\n",
    "        model=tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=((80,80,1))),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init,\n",
    "                                   strides=2),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init,\n",
    "                                   strides=2),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(256,\n",
    "                                   kernel_size=4,\n",
    "                                   padding=\"same\",\n",
    "                                   use_bias=False,\n",
    "                                   kernel_initializer=self.init,\n",
    "                                   strides=2),\n",
    "\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(1,kernel_size=4,kernel_initializer=self.init),\n",
    "\n",
    "            tf.keras.layers.Flatten()])\n",
    "\n",
    "        return model\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self,imgs_real):\n",
    "        \"\"\"1. генератор принимает вектор нормального распределения и выдает фейк.данные\n",
    "           2. дискриминатор принимает фейк.данные генератора и реальные данные\n",
    "           3. выход дискриминатора на реальных и фейк.данных едет в discriminator_loss\n",
    "           4. выход дискриминатора на фейк.данных едет в generator_loss\n",
    "           5. с помощью лосса генератора и обученных параметров генератора\n",
    "           считается градиент для генератора. аналогично для дискриминатора\n",
    "           6. оба градиента пробрасываются в оптимайзер\"\"\"\n",
    "        random_normal_vector=tf.random.normal([tf.cast(imgs_real.shape[0],tf.int32),200])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
    "            imgs_generated=self.gen(random_normal_vector,training=True)\n",
    "\n",
    "            output_real=self.disc(imgs_real,training=True)\n",
    "            output_fake=self.disc(imgs_generated,training=True)\n",
    "\n",
    "            loss_gen=self.loss_gen(output_fake)\n",
    "            loss_disc=self.loss_disc(output_real,output_fake)\n",
    "\n",
    "        grads_of_gen=gen_tape.gradient(loss_gen,self.gen.trainable_variables)\n",
    "        grads_of_disc=disc_tape.gradient(loss_disc,self.disc.trainable_variables)\n",
    "\n",
    "        self.opti.apply_gradients(zip(grads_of_gen,self.gen.trainable_variables))\n",
    "        self.opti.apply_gradients(zip(grads_of_disc,self.disc.trainable_variables))\n",
    "\n",
    "    def train(self,data):\n",
    "        \"\"\"каждую итерацию один батч реальных данных едет в метод train_step,\n",
    "        откуда поедет на вход дискриминатора\"\"\"\n",
    "        for epoch in range(5):\n",
    "            for batch in tqdm(data):\n",
    "                self.train_step(batch)\n",
    "\n",
    "gan=Gan()\n",
    "\n",
    "path='C:/Users/gimaevra94/Documents/local/gan/data'\n",
    "#path='content/'\n",
    "\n",
    "data=pathlib.Path(path).parent/'data'\n",
    "data2=data/'data2'\n",
    "data3=data2/'data3'\n",
    "\n",
    "train=tf.keras.utils.image_dataset_from_directory(directory=data2,\n",
    "                                                  label_mode=None,\n",
    "                                                  batch_size=256,\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  image_size=(80,80))\n",
    "\n",
    "rescale=tf.keras.layers.Rescaling(1./127.5,offset=-1)\n",
    "train=train.map(lambda x:rescale(x))\n",
    "\n",
    "gan.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b558723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_11 (Reshape)        (None, 1, 1, 200)         0         \n",
      "                                                                 \n",
      " up_sampling2d_44 (UpSampli  (None, 10, 10, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 10, 10, 256)       819200    \n",
      "                                                                 \n",
      " batch_normalization_60 (Ba  (None, 10, 10, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_60 (LeakyReLU)  (None, 10, 10, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_45 (UpSampli  (None, 20, 20, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 20, 20, 128)       524288    \n",
      "                                                                 \n",
      " batch_normalization_61 (Ba  (None, 20, 20, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_61 (LeakyReLU)  (None, 20, 20, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_46 (UpSampli  (None, 40, 40, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 40, 40, 64)        131072    \n",
      "                                                                 \n",
      " batch_normalization_62 (Ba  (None, 40, 40, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_62 (LeakyReLU)  (None, 40, 40, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_47 (UpSampli  (None, 80, 80, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 80, 80, 1)         1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1477377 (5.64 MB)\n",
      "Trainable params: 1476481 (5.63 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.gen.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
